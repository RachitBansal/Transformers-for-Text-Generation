{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-Transformers-1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcze2U8Q0UCb",
        "colab_type": "text"
      },
      "source": [
        "**Sentence Completion using GPT2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl6--_vcS_6c",
        "colab_type": "code",
        "outputId": "01a9a1ef-3c01-4c3f-da59-e42691ee6d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "!pip3 install pytorch-transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 3.5MB/s \n",
            "\u001b[?25hCollecting sacremoses (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 39.4MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.236)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.236 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.236)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->pytorch-transformers) (2.5.3)\n",
            "Building wheels for collected packages: sacremoses, regex\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=ed6ed2dd0c885f660927a05a0c15e016fd373c3238c6715b95ff0fe2e3d03450\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609233 sha256=c37dd2d4521d9635dee45f203226f06b7cfce06dd37e79bec10d769abf3c8c4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built sacremoses regex\n",
            "Installing collected packages: sacremoses, regex, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.35 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2prlCOMTGIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YypDS457TGck",
        "colab_type": "code",
        "outputId": "97958200-200d-459b-f056-bba3b51ee81b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "tokeniser = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1042301/1042301 [00:00<00:00, 5489402.55B/s]\n",
            "100%|██████████| 456318/456318 [00:00<00:00, 4057494.56B/s]\n",
            "100%|██████████| 176/176 [00:00<00:00, 108002.56B/s]\n",
            "100%|██████████| 548118077/548118077 [00:11<00:00, 48989218.67B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m1AHRH81gx1",
        "colab_type": "text"
      },
      "source": [
        "**One word completion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH7ANyR9TFa4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c21ce675-8474-4fa0-b4a8-1f163c0fea42"
      },
      "source": [
        "text = \"who is your\"\n",
        "indexed_tokens = tokeniser.encode(text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "model.eval() # Setting the model in evaluation mode to deactivate the DropOut modules\n",
        "tokens_tensor = tokens_tensor.to('cuda')\n",
        "model.to('cuda')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMocBix7UUWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(tokens_tensor)\n",
        "  predictions = outputs[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCU48FlIVBth",
        "colab_type": "code",
        "outputId": "c168514f-803c-401d-b522-4125d0606431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(outputs[0].shape)\n",
        "print(predictions)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 50257])\n",
            "tensor([[[ -41.9926,  -42.0111,  -45.8861,  ...,  -47.4671,  -46.0255,\n",
            "           -41.8869],\n",
            "         [-118.9843, -117.2208, -123.5588,  ..., -123.6198, -122.7697,\n",
            "          -120.4119],\n",
            "         [-105.8518, -104.3982, -108.1491,  ..., -106.3690, -109.4703,\n",
            "          -104.2819]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5K9R9D1Uc72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "predicted_text = tokeniser.decode(indexed_tokens + [predicted_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3DTADtUtUn",
        "colab_type": "code",
        "outputId": "7aad81dc-30ed-4be6-b3e7-32bfd06b331f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(predicted_text)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " who is your friend\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i215__Qk1qB8",
        "colab_type": "text"
      },
      "source": [
        "**Muliple Word Completion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c__8-Aa7VgP2",
        "colab_type": "code",
        "outputId": "a8346bd4-556d-4cc0-dffe-dee6d7a60778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "chars = 0\n",
        "text = \"who is responsible\"\n",
        "while chars<20:\n",
        "  chars += 1\n",
        "  indexed_tokens = tokeniser.encode(text)\n",
        "  tokens_tensors = torch.tensor([indexed_tokens])\n",
        "  tokens_tensors = tokens_tensors.to('cuda')\n",
        "#  model = model.to('cuda')\n",
        "  with torch.no_grad():\n",
        "    outputs = model(tokens_tensors)\n",
        "    predictions = outputs[0]\n",
        "  predicted_index = torch.argmax(predictions[0,-1,:]).item()\n",
        "  text = tokeniser.decode(indexed_tokens + [predicted_index])\n",
        "\n",
        "print(text)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " who is responsible for the development of the new technology.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIaKrhY-0knA",
        "colab_type": "text"
      },
      "source": [
        "**Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0v8jnuBnyUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "91ef3664-d5e1-4159-e3ce-0985ad314410"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/99/ca0e4c35ccde7d290de3c9c236d5629d1879b04927e5ace9bd6d9183e236/transformers-2.0.0-py3-none-any.whl (290kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.8.19)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.9.236)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.16.5)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.236 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.12.236)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->transformers) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->transformers) (0.15.2)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmzAWnqqm9Tn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2d4a5841-8319-4f4a-febd-c70373393b69"
      },
      "source": [
        "!git clone https://github.com/huggingface/pytorch-transformers.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-transformers'...\n",
            "remote: Enumerating objects: 9922, done.\u001b[K\n",
            "remote: Total 9922 (delta 0), reused 0 (delta 0), pack-reused 9922\n",
            "Receiving objects: 100% (9922/9922), 5.08 MiB | 18.72 MiB/s, done.\n",
            "Resolving deltas: 100% (7232/7232), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2MIoRD9nSi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "2a31cac2-9d3c-4227-b4ed-59b4d17332eb"
      },
      "source": [
        "!python pytorch-transformers/examples/run_generation.py "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"pytorch-transformers/examples/run_generation.py\", line 29, in <module>\n",
            "    from transformers import GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig, XLMConfig\n",
            "ModuleNotFoundError: No module named 'transformers'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbuz7UkRvack",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "5172cf0f-41c0-4cbc-df44-d26af4403f88"
      },
      "source": [
        "!python pytorch-transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=gpt2 \\"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/06/2019 20:39:59 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "10/06/2019 20:39:59 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "10/06/2019 20:39:59 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n",
            "10/06/2019 20:39:59 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pruned_heads\": {},\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "10/06/2019 20:39:59 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "Namespace(device=device(type='cuda'), length=100, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, padding_text='', prompt='', seed=42, stop_token=None, temperature=1.0, top_k=0, top_p=0.9, xlm_lang='')\n",
            "Model prompt >>> The political situation in the country is quite disturbing, with pigs occupying the major positions and others chanting his name like god\n",
            "100% 100/100 [00:02<00:00, 34.04it/s]\n",
            " and rescuing civilians from the street. The rules of government are very clear. Now imagine a Muslim government that if forced to support four or five hundred people and hand over their arms to those who kill them, the public would vote for the 'illegal and inhuman'. And the victims would feel 'condolences', while the attackers seek revenge for their crimes. On that same day in 1982, President George H.W. Bush was invited by the communists to the United States to look at the effects of\n",
            "Model prompt >>> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9hbkz5zuac5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "d2358ffb-6138-4ef2-d690-84e0a900e395"
      },
      "source": [
        "!python pytorch-transformers/examples/run_generation.py \\\n",
        "    --model_type=xlnet \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=xlnet-base-cased \\"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/06/2019 20:42:09 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /root/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n",
            "10/06/2019 20:42:09 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /root/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.ef1824921bc0786e97dc88d55eb17aabf18aac90f24bd34c0650529e7ba27d6f\n",
            "10/06/2019 20:42:09 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_token\": 32000,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pruned_heads\": {},\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"untie_r\": true,\n",
            "  \"use_bfloat16\": false\n",
            "}\n",
            "\n",
            "10/06/2019 20:42:09 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac\n",
            "The political situation in the country is quite disturbing, with pigs occupying the major positions and others chanting his name like god\n",
            "Namespace(device=device(type='cuda'), length=100, model_name_or_path='xlnet-base-cased', model_type='xlnet', n_gpu=1, no_cuda=False, padding_text='', prompt='', seed=42, stop_token=None, temperature=1.0, top_k=0, top_p=0.9, xlm_lang='')\n",
            "100% 100/100 [00:09<00:00,  8.61it/s]\n",
            "-given thunder. But it is not only a fall of the president, but also the rise of the leader who he has marked and converted. Stephen Geerts You know what I mean. I was in Florida when I first came across this edition of our \"Tu Voit Tom\" website, which has moved rapidly over the past few months, but was made final today. To me, this is a \"grass verge\" affair, and that is well-known and very popular\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"pytorch-transformers/examples/run_generation.py\", line 220, in <module>\n",
            "    main()\n",
            "  File \"pytorch-transformers/examples/run_generation.py\", line 192, in main\n",
            "    raw_text = args.prompt if args.prompt else input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSwbeSgzm_QK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "b4507d9a-32fa-4292-98de-82f797ac6953"
      },
      "source": [
        "!python pytorch-transformers/examples/run_generation.py \\\n",
        "    --model_type=transfo-xl \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=transfo-xl-wt103 \\"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/06/2019 20:43:02 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/transfo-xl-wt103-vocab.bin from cache at /root/.cache/torch/transformers/b24cb708726fd43cbf1a382da9ed3908263e4fb8a156f9e0a4f45b7540c69caa.a6a9c41b856e5c31c9f125dd6a7ed4b833fbcefda148b627871d4171b25cffd1\n",
            "10/06/2019 20:43:02 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/transfo-xl-wt103-config.json from cache at /root/.cache/torch/transformers/a6dfd6a3896b3ae4c1a3c5f26ff1f1827c26c15b679de9212a04060eaf1237df.aef76fb1064c932cd6a2a2be3f23ebbfa5f9b6e29e8e87b571c45b4a5d5d1b90\n",
            "10/06/2019 20:43:02 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"adaptive\": true,\n",
            "  \"attn_type\": 0,\n",
            "  \"clamp_len\": 1000,\n",
            "  \"cutoffs\": [\n",
            "    20000,\n",
            "    40000,\n",
            "    200000\n",
            "  ],\n",
            "  \"d_embed\": 1024,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 4096,\n",
            "  \"d_model\": 1024,\n",
            "  \"div_val\": 4,\n",
            "  \"dropatt\": 0.0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"ext_len\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"init\": \"normal\",\n",
            "  \"init_range\": 0.01,\n",
            "  \"init_std\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"mem_len\": 1600,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 18,\n",
            "  \"n_token\": 267735,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pre_lnorm\": false,\n",
            "  \"proj_init_std\": 0.01,\n",
            "  \"pruned_heads\": {},\n",
            "  \"same_length\": true,\n",
            "  \"sample_softmax\": -1,\n",
            "  \"tgt_len\": 128,\n",
            "  \"tie_projs\": [\n",
            "    false,\n",
            "    true,\n",
            "    true,\n",
            "    true\n",
            "  ],\n",
            "  \"tie_weight\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"untie_r\": true,\n",
            "  \"use_bfloat16\": false\n",
            "}\n",
            "\n",
            "10/06/2019 20:43:03 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/transfo-xl-wt103-pytorch_model.bin from cache at /root/.cache/torch/transformers/12642ff7d0279757d8356bfd86a729d9697018a0c93ad042de1d0d2cc17fd57b.e9704971f27275ec067a00a67e6a5f0b05b4306b3f714a96e9f763d8fb612671\n",
            "The political situation in the country is quite disturbing, with pigs occupying the major positions and others chanting his name like god\n",
            "Namespace(device=device(type='cuda'), length=100, model_name_or_path='transfo-xl-wt103', model_type='transfo-xl', n_gpu=1, no_cuda=False, padding_text='', prompt='', seed=42, stop_token=None, temperature=1.0, top_k=0, top_p=0.9, xlm_lang='')\n",
            "100% 100/100 [00:43<00:00,  2.04it/s]\n",
            "Odin or Yama in. The case is one of serious crime, as according to the JTWC, \" one can only be convicted of violent conduct and thus have his capital punishment suspended \". When the case was first presented to the International Court of Justice on 21 November 2010, its judges rejected it, stating that their opinion had neither been understood nor tested and necessary to allow the proceedings to proceed. The court decided on 18 May 2011 that defendants had forfeited their right to be tried, and in October 2011\n",
            "Model prompt >>> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guu1jSA3yGat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}